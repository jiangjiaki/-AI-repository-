{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7LHkvp3_qTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "\n",
        "#parameters for LSTM\n",
        "nb_lstm_outputs = 30  \n",
        "nb_time_steps = 28  \n",
        "nb_input_vector = 28 \n",
        "\n",
        "#data preprocessing: tofloat32, normalization, one_hot encoding\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        " \n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "#build model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=nb_lstm_outputs, input_shape=(nb_time_steps, nb_input_vector)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#compile:loss, optimizer, metrics\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#train: epcoch, batch_size\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=128, verbose=1)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "score = model.evaluate(x_test, y_test,batch_size=128, verbose=1)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}